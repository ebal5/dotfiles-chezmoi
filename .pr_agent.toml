[config]
model = " llama-3.1-70b-versatile"
model_turbo = " llama-3.1-70b-versatile"
fallback_models = ["llama3-70b-8192"]
# custom_model_max_tokens = 100000

[pr_reviewer]
require_score_review=true
require_estimate_effort_to_review=true
require_security_review=true
extra_instructions="日本語でレビューを行ってください。"

[pr_description]
extra_instructions="日本語でプルリクエストの説明を行ってください。"

[pr_code_suggestions]
extra_instructions="日本語でコードの改善提案を行ってください。"

[pr_add_docs]
extra_instructions="日本語でドキュメントを追加してください。"

[pr_update_changelog]
extra_instructions="日本語でチェンジログを更新してください。"

[pr_test]
extra_instructions="日本語でテストコードを追加してください。"

[pr_improve_component]
extra_instructions="日本語でコンポーネントの改善提案を行ってください。"
